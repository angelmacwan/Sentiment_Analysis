{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f508d9b-9419-41f0-9159-aed522d96330",
   "metadata": {},
   "source": [
    "# Sentiment Analysis\n",
    "## Data Processing\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37342586-349a-46d5-85b1-6e4be2e857c9",
   "metadata": {},
   "source": [
    "### Remove stop words and Remove unwanted text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "434c1f24-b900-4f06-95aa-766ab9ba3f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import re\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce2f71b7-21c6-47fa-b001-250cad2ecc67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.53 s, sys: 229 ms, total: 2.76 s\n",
      "Wall time: 3.45 s\n"
     ]
    }
   ],
   "source": [
    "# Load Data\n",
    "%time data = pd.read_csv(\"./DATA/DATA.csv\", header=None)\n",
    "data = data.drop(columns=[1,2,3,4])\n",
    "data = data.rename(columns={0: \"label\", 5: \"tweet\"})\n",
    "X = np.array(data.tweet) # X => Sentence\n",
    "Y = np.array(data.label) # Y => Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c662d683-2938-4278-b6eb-59f79b3127f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# regex patern for twitter handle and mention @\\w+\n",
    "# regex patern for attachment url http://\\w+.com/\\w+\n",
    "\n",
    "def cleanText(wordList):\n",
    "    t1 = time.time()\n",
    "    for i in range(len(wordList)):\n",
    "        temp = word_tokenize(wordList[i]) \n",
    "        temp = [j for j in wordList[i] if i not in stopwords.words(\"english\")]\n",
    "        wordList[i] = \"\".join(temp)\n",
    "        wordList[i] = re.sub(\"@\\w+\", '', wordList[i])\n",
    "        wordList[i] = re.sub(\"http://\\w+.com/\\w+\", '', wordList[i])\n",
    "    t2 = time.time()\n",
    "    print(f\"Time taken  => {t2-t1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "17628c39-7533-475e-bd0e-a82cb5ed17a8",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "itteration 1/50\n",
      "itteration 2/50\n",
      "itteration 3/50\n",
      "itteration 4/50\n",
      "itteration 5/50\n",
      "itteration 6/50\n",
      "itteration 7/50\n",
      "itteration 8/50\n",
      "itteration 9/50\n",
      "itteration 10/50\n",
      "itteration 11/50\n",
      "itteration 12/50\n",
      "itteration 13/50\n",
      "itteration 14/50\n",
      "itteration 15/50\n",
      "itteration 16/50\n",
      "itteration 17/50\n",
      "itteration 18/50\n",
      "itteration 19/50\n",
      "itteration 20/50\n",
      "itteration 21/50\n",
      "itteration 22/50\n",
      "itteration 23/50\n",
      "itteration 24/50\n",
      "itteration 25/50\n",
      "itteration 26/50\n",
      "itteration 27/50\n",
      "itteration 28/50\n",
      "itteration 29/50\n",
      "itteration 30/50\n",
      "itteration 31/50\n",
      "itteration 32/50\n",
      "itteration 33/50\n",
      "itteration 34/50\n",
      "itteration 35/50\n",
      "itteration 36/50\n",
      "itteration 37/50\n",
      "itteration 38/50\n",
      "itteration 39/50\n",
      "itteration 40/50\n",
      "itteration 41/50\n",
      "itteration 42/50\n",
      "itteration 43/50\n",
      "itteration 44/50\n",
      "itteration 45/50\n",
      "itteration 46/50\n",
      "itteration 47/50\n",
      "itteration 48/50\n",
      "itteration 49/50\n",
      "itteration 50/50\n"
     ]
    }
   ],
   "source": [
    "# processing in chunks\n",
    "n = 50 # number of chunks\n",
    "count = 1\n",
    "for i in range(0, len(X)+1-len(X)//n, len(X)//n):\n",
    "    print(f\"itteration {count}/{n}\")\n",
    "    count += 1\n",
    "    start,end = i, i+len(X)//n\n",
    "    cleanText(X[start:end+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "894a066c-109a-4a6d-a8f5-739866d17dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(list(zip(X, Y)), columns =['tweet', 'label'])\n",
    "data.to_csv(\"./DataProcessingStep01.csv\", sep=\",\") # save data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c0e13c-cd7e-4956-873e-37f345de4397",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
