{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis\n",
    "## Data Formatting and Model Training\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.text import tokenizer_from_json\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import h5py\n",
    "\n",
    "import io\n",
    "import json\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Loading data\n",
    "# data = pd.read_csv(\"../input/sentimentanalysisprojectdata/ProcesseData.csv\")\n",
    "data = pd.read_csv(\"./ProcessedData.csv\")\n",
    "\n",
    "data = data.drop(columns=[\"Unnamed: 0\"])\n",
    "X = list(data.tweet) # X => Sentence\n",
    "Y = list(data.label) # Y => Sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Splitting Data into Train and Test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 0 -> Negative, 1 -> Positive\n",
    "Y = [1 if i!=0 else i for i in Y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 33% data will be used for testing\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.33, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-24T07:34:30.593718Z",
     "iopub.status.busy": "2021-06-24T07:34:30.593146Z",
     "iopub.status.idle": "2021-06-24T07:34:30.626712Z",
     "shell.execute_reply": "2021-06-24T07:34:30.625938Z",
     "shell.execute_reply.started": "2021-06-24T07:34:30.593681Z"
    }
   },
   "source": [
    "---\n",
    "## Tokenizing, Sequencing and Padding\n",
    "\n",
    "### 01 Tokenizing\n",
    "Tokenizing is the mapping of words to numbers. \n",
    "\n",
    "`Tokenizer()` in tensorflow generates a dictionary of keys as words and its values are unique numbers\n",
    "\n",
    "`tokenizer.word_index` stores the generated dictionary\n",
    "\n",
    "**This will be done only on train set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 22.3 s, sys: 66.4 ms, total: 22.4 s\n",
      "Wall time: 22.4 s\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 30000\n",
    "embedding_dim = 16\n",
    "max_length = 200\n",
    "trunc_type='post'\n",
    "padding_type='post'\n",
    "oov_tok = \"<OOV>\"\n",
    "\n",
    "tokenizer = Tokenizer(num_words=vocab_size, oov_token=oov_tok)\n",
    "%time tokenizer.fit_on_texts(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "word_index = tokenizer.word_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the tokenizer as ot will be used for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_json = tokenizer.to_json()\n",
    "with io.open('tokenizer.json', 'w', encoding='utf-8') as f:\n",
    "    f.write(json.dumps(tokenizer_json, ensure_ascii=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load tokenizer\n",
    "<pre>\n",
    "with open('tokenizer.json') as f:\n",
    "    data = json.load(f)\n",
    "    tokenizer = tokenizer_from_json(data)\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 02 Sequencing and Padding\n",
    "\n",
    "`Tokenizer()` object can be used to convert strings to numbers once it is fit corpus of text\n",
    "\n",
    "`tokenizer.texts_to_sequences()` method will map words to its currosponding int value from word_index\n",
    "\n",
    "Padding is used to convert all tokenized strings to the same length so that ML Models can use it as input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sequencing and Padding Train Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_seq = tokenizer.texts_to_sequences(X_train)\n",
    "train_padSeq = pad_sequences(train_seq, maxlen=max_length, padding=padding_type, truncating=trunc_type) # padSeq can be used as input to train a mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sqeuencing and Padding Test Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_seq = tokenizer.texts_to_sequences(X_test)\n",
    "test_padSeq = pad_sequences(test_seq, maxlen=max_length, padding=padding_type, truncating=trunc_type) # padSeq can be used as input to train a mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## NeutalNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1st layer is an Embedding layer where direction of each word will be learned per epoc\n",
    "\n",
    "Pooling is done using `GlobalAveragePoling1D()`\n",
    "\n",
    "Dense layer is the Deep Neural Network, in which 1st layer have an Activation of `relu` or Rectify Linear which is a Linear activationn layer\n",
    "\n",
    "The 2nd dense layer is a `sigmoid` activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
    "    tf.keras.layers.GlobalAveragePooling1D(),\n",
    "    tf.keras.layers.Dense(24, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting data to np array\n",
    "train_padSeq = np.array(train_padSeq)\n",
    "test_padSeq = np.array(test_padSeq)\n",
    "\n",
    "Y_train = np.array(Y_train)\n",
    "Y_test = np.array(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "33500/33500 [==============================] - 128s 4ms/step - loss: 0.4663 - accuracy: 0.7825 - val_loss: 0.4323 - val_accuracy: 0.8005\n",
      "Epoch 2/30\n",
      "33500/33500 [==============================] - 130s 4ms/step - loss: 0.4266 - accuracy: 0.8035 - val_loss: 0.4255 - val_accuracy: 0.8038\n",
      "Epoch 3/30\n",
      "33500/33500 [==============================] - 127s 4ms/step - loss: 0.4183 - accuracy: 0.8079 - val_loss: 0.4235 - val_accuracy: 0.8061\n",
      "Epoch 4/30\n",
      "33500/33500 [==============================] - 127s 4ms/step - loss: 0.4122 - accuracy: 0.8116 - val_loss: 0.4219 - val_accuracy: 0.8076\n",
      "Epoch 5/30\n",
      "33500/33500 [==============================] - 129s 4ms/step - loss: 0.4076 - accuracy: 0.8146 - val_loss: 0.4232 - val_accuracy: 0.8080\n",
      "Epoch 6/30\n",
      "33500/33500 [==============================] - 128s 4ms/step - loss: 0.4034 - accuracy: 0.8172 - val_loss: 0.4217 - val_accuracy: 0.8085\n",
      "Epoch 7/30\n",
      "33500/33500 [==============================] - 128s 4ms/step - loss: 0.3998 - accuracy: 0.8191 - val_loss: 0.4222 - val_accuracy: 0.8086\n",
      "Epoch 8/30\n",
      "33500/33500 [==============================] - 131s 4ms/step - loss: 0.3964 - accuracy: 0.8208 - val_loss: 0.4236 - val_accuracy: 0.8078\n",
      "Epoch 9/30\n",
      "33500/33500 [==============================] - 132s 4ms/step - loss: 0.3933 - accuracy: 0.8225 - val_loss: 0.4264 - val_accuracy: 0.8074\n",
      "Epoch 10/30\n",
      "33500/33500 [==============================] - 130s 4ms/step - loss: 0.3904 - accuracy: 0.8240 - val_loss: 0.4281 - val_accuracy: 0.8063\n",
      "Epoch 11/30\n",
      "33500/33500 [==============================] - 130s 4ms/step - loss: 0.3876 - accuracy: 0.8257 - val_loss: 0.4270 - val_accuracy: 0.8064\n",
      "Epoch 12/30\n",
      "33500/33500 [==============================] - 134s 4ms/step - loss: 0.3847 - accuracy: 0.8273 - val_loss: 0.4312 - val_accuracy: 0.8040\n",
      "Epoch 13/30\n",
      "33500/33500 [==============================] - 132s 4ms/step - loss: 0.3820 - accuracy: 0.8285 - val_loss: 0.4272 - val_accuracy: 0.8066\n",
      "Epoch 14/30\n",
      "33500/33500 [==============================] - 142s 4ms/step - loss: 0.3795 - accuracy: 0.8301 - val_loss: 0.4301 - val_accuracy: 0.8052\n",
      "Epoch 15/30\n",
      "33500/33500 [==============================] - 135s 4ms/step - loss: 0.3769 - accuracy: 0.8313 - val_loss: 0.4339 - val_accuracy: 0.8050\n",
      "Epoch 16/30\n",
      "33500/33500 [==============================] - 143s 4ms/step - loss: 0.3743 - accuracy: 0.8329 - val_loss: 0.4358 - val_accuracy: 0.8042\n",
      "Epoch 17/30\n",
      "33500/33500 [==============================] - 133s 4ms/step - loss: 0.3719 - accuracy: 0.8340 - val_loss: 0.4336 - val_accuracy: 0.8048\n",
      "Epoch 18/30\n",
      "33500/33500 [==============================] - 131s 4ms/step - loss: 0.3697 - accuracy: 0.8354 - val_loss: 0.4344 - val_accuracy: 0.8046\n",
      "Epoch 19/30\n",
      "33500/33500 [==============================] - 141s 4ms/step - loss: 0.3672 - accuracy: 0.8367 - val_loss: 0.4391 - val_accuracy: 0.8028\n",
      "Epoch 20/30\n",
      "33500/33500 [==============================] - 133s 4ms/step - loss: 0.3648 - accuracy: 0.8380 - val_loss: 0.4409 - val_accuracy: 0.8025\n",
      "Epoch 21/30\n",
      "33500/33500 [==============================] - 135s 4ms/step - loss: 0.3624 - accuracy: 0.8394 - val_loss: 0.4426 - val_accuracy: 0.7996\n",
      "Epoch 22/30\n",
      "33500/33500 [==============================] - 136s 4ms/step - loss: 0.3602 - accuracy: 0.8403 - val_loss: 0.4432 - val_accuracy: 0.8014\n",
      "Epoch 23/30\n",
      "33500/33500 [==============================] - 143s 4ms/step - loss: 0.3578 - accuracy: 0.8414 - val_loss: 0.4447 - val_accuracy: 0.8022\n",
      "Epoch 24/30\n",
      "33500/33500 [==============================] - 144s 4ms/step - loss: 0.3556 - accuracy: 0.8430 - val_loss: 0.4487 - val_accuracy: 0.7999\n",
      "Epoch 25/30\n",
      "33500/33500 [==============================] - 139s 4ms/step - loss: 0.3534 - accuracy: 0.8441 - val_loss: 0.4508 - val_accuracy: 0.8010\n",
      "Epoch 26/30\n",
      "33500/33500 [==============================] - 142s 4ms/step - loss: 0.3512 - accuracy: 0.8451 - val_loss: 0.4538 - val_accuracy: 0.8001\n",
      "Epoch 27/30\n",
      "33500/33500 [==============================] - 144s 4ms/step - loss: 0.3489 - accuracy: 0.8464 - val_loss: 0.4521 - val_accuracy: 0.8005\n",
      "Epoch 28/30\n",
      "33500/33500 [==============================] - 138s 4ms/step - loss: 0.3469 - accuracy: 0.8477 - val_loss: 0.4556 - val_accuracy: 0.7982\n",
      "Epoch 29/30\n",
      "33500/33500 [==============================] - 138s 4ms/step - loss: 0.3450 - accuracy: 0.8486 - val_loss: 0.4654 - val_accuracy: 0.7977\n",
      "Epoch 30/30\n",
      "33500/33500 [==============================] - 137s 4ms/step - loss: 0.3431 - accuracy: 0.8497 - val_loss: 0.4628 - val_accuracy: 0.7984\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 30\n",
    "\n",
    "# Training the model with 20 epochs\n",
    "# (used to gain insignt on model training) verbose =  0 => silent  /  1 => progress bar  /  2 => one line per epoch\n",
    "history = model.fit(train_padSeq, Y_train, epochs = n_epochs, validation_data = (test_padSeq, Y_test), verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the model after training\n",
    "model.save(\"SentimentModel01.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 200, 16)           480000    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d (Gl (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 24)                408       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 25        \n",
      "=================================================================\n",
      "Total params: 480,433\n",
      "Trainable params: 480,433\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy 79.83920574188232\n",
      "test loss 46.279966831207275\n",
      "train accuracy 85.24841666221619\n",
      "train loss 33.66129994392395\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(test_padSeq, Y_test, verbose=0)\n",
    "print(f\"test accuracy {test_acc*100}\")\n",
    "print(f\"test loss {test_loss*100}\")\n",
    "\n",
    "train_loss, train_acc = model.evaluate(train_padSeq, Y_train, verbose=0)\n",
    "\n",
    "print(f\"train accuracy {train_acc*100}\")\n",
    "print(f\"train loss {train_loss*100}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loadMode = tf.keras.models.load_model('<MODEL NAME>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load tokenizer and model before making to use the model\n",
    "\n",
    "# Load Tokenizer\n",
    "with open('tokenizer.json') as f:\n",
    "    data = json.load(f)\n",
    "    tokenizer = tokenizer_from_json(data)\n",
    "\n",
    "model = tf.keras.models.load_model(\"./SentimentModel01.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictSentiment(x):\n",
    "    sequences = tokenizer.texts_to_sequences(x)\n",
    "    padded = pad_sequences(sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
    "    return model.predict(padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.99324006],\n",
       "       [0.67132217]], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictSentiment([\"Hi there, how are you\", \"if you dont have errors while importing h5py you are good to save\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "plt.bar([\"TestLoss\", \"TestAccuracy\", \"TrainLoss\", \"TrainAccruacy\"],\n",
    "        [test_loss, test_acc, train_loss, train_acc],\n",
    "        width=0.5,\n",
    "        color=[\"#fcb103\", \"#fcb103\", \"#00f5a7\", \"#00f5a7\"])\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
